{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import classiq\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # Add the parent directory to the sys.path list\n",
    "\n",
    "from models.leqm3 import linear_entanglement_r3_quantum_model\n",
    "from models.qnn import execute_fn, post_process_fn, QNN\n",
    "\n",
    "from scripts.helper import create_writer, write_train_results\n",
    "from scripts.data_setup import create_dataloaders_from_folders\n",
    "from scripts.data_transforms import input_transform, target_transform\n",
    "from scripts.train import train\n",
    "from scripts.test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The current version of 'classiq' has been deprecated, and will not be supported as of 2024-01-18. Please run \"pip install -U classiq\" to upgrade the classiq SDK to the latest version.\n",
      "/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/classiq/_internals/authentication/token_manager.py:82: UserWarning: Device is already registered.\n",
      "Generating a new refresh token should only be done if the current refresh token is compromised.\n",
      "To do so, set the overwrite parameter to true\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Authenticate Classiq\n",
    "classiq.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For setting up device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clear Output Files\n",
    "post_process_output_file = open(\"post_process_output.txt\", \"w\")\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------\", file=post_process_output_file)\n",
    "print(\"--------------------------------------------POST PROCESS OUTPUT--------------------------------------------------\", file=post_process_output_file)\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------\", file=post_process_output_file)\n",
    "post_process_output_file.close()\n",
    "\n",
    "test_loop_output_file = open(\"test_loop_output.txt\", \"w\")\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------\", file=test_loop_output_file)\n",
    "print(\"-----------------------------------------------TEST LOOP OUTPUT--------------------------------------------------\", file=test_loop_output_file)\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------\", file=test_loop_output_file)\n",
    "test_loop_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER PARAMETERS\n",
    "_LEARNING_RATE = 1.0\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a Linear Entanglement Quantum Model for MNIST Data Classification with three linear entanglement layers of RXX, RYY, and RZZ.\n",
    "quantum_model = linear_entanglement_r3_quantum_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantum_program = classiq.synthesize(quantum_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: https://platform.classiq.io/circuit/ca968b8e-89ea-4964-99cc-d2bf74f6df9b?version=0.33.0\n"
     ]
    }
   ],
   "source": [
    "# View Quantum Program on Classiq Platform\n",
    "classiq.show(quantum_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: https://platform.classiq.io/circuit/ca968b8e-89ea-4964-99cc-d2bf74f6df9b?version=0.33.0: Operation not supported\n"
     ]
    }
   ],
   "source": [
    "qnn = QNN(\n",
    "    quantum_program=quantum_program,\n",
    "    execute=execute_fn,\n",
    "    post_process=post_process_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model=qnn, input_size=(32, 16), verbose=0, col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], col_width=20, row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing our loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "# choosing our optimizer\n",
    "optimizer = optim.SGD(qnn.parameters(), lr=_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataloaders_from_folders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataloader, test_dataloader, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataloaders_from_folders\u001b[49m(\n\u001b[1;32m      2\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     transform\u001b[38;5;241m=\u001b[39minput_transform,\n\u001b[1;32m      4\u001b[0m     target_transform\u001b[38;5;241m=\u001b[39mtarget_transform,\n\u001b[1;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m      6\u001b[0m     create_subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     subset_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_dataloaders_from_folders' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataloader, test_dataloader, class_names = create_dataloaders_from_folders(\n",
    "    root=\"data\",\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    create_subset=True,\n",
    "    subset_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Our Dataset have following classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Image shape: {data.shape} -> [batch_size, pixel_angle]\")\n",
    "print(f\"Label shape: {label.shape} -> [batch_size, label_value]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 01. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a writer for tracking our experiment\n",
    "writer = create_writer(experiment_name=\"data_0.1_percent\", model_name=\"linear_entanglement_r3\", extra=f\"{EPOCHS}_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = train(\n",
    "    model = qnn, \n",
    "    data_loader = train_dataloader, \n",
    "    loss_fn = loss_fn, \n",
    "    optimizer = optimizer, \n",
    "    writer = writer, \n",
    "    epochs = EPOCHS,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the model results\n",
    "print(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_train_results(experiment_name=\"data_0.1_percent\", model_name=\"linear_entanglement_r3\", epochs=EPOCHS, results=train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test(\n",
    "    model = qnn, \n",
    "    data_loader = test_dataloader,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\n",
    "    model=qnn,\n",
    "    target_dir='outputs/saved_models',\n",
    "    model_name='leqmr3_subset64'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
