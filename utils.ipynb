{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilkillerag/document/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/classiq/_internals/authentication/token_manager.py:82: UserWarning: Device is already registered.\n",
      "Generating a new refresh token should only be done if the current refresh token is compromised.\n",
      "To do so, set the overwrite parameter to true\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "import classiq\n",
    "from classiq import Model, QReg, RX, RY, RZ, synthesize\n",
    "from classiq.builtin_functions import HardwareEfficientAnsatz\n",
    "classiq.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_NUM_QUBITS = 4\n",
    "_CONNECTIVITY_MAP = \"circular\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classical Layer for Image Commpression:\n",
    "The input MNIST images are all 28 × 28. This Classical Layer will firstly center-crop them to 24 × 24 and\n",
    "then down-sample them to 4 × 4 for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalCompressionLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassicalCompressionLayer, self).__init__()\n",
    "        self.center_crop = transforms.CenterCrop((24, 24))\n",
    "        self.down_sample = transforms.Resize((4, 4))\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.center_crop(x)\n",
    "        x = self.down_sample(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantum Layer for Encoding \n",
    "The output of Classical Compression Layer is encoded by this quantum layer into a quantum circuit. We use Angle encoding to encode 4 pixels per qubit using RX, RY, RZ, and RX gate on each qubit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumEncodingLayer(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def encode_pixels(self, pixel_values: torch.Tensor) -> Dict[str, QReg]:\n",
    "        # Split pixel values into groups of 4\n",
    "        pixel_groups = pixel_values.split(4)\n",
    "        \n",
    "        # Initialize dictionary to store qubit outputs\n",
    "        qubit_outputs = {}\n",
    "        \n",
    "        # Encode each group of 4 pixels into angles for RX, RY, RZ, RX gates\n",
    "        for i, pixel_group in enumerate(pixel_groups):\n",
    "            rx_angle = pixel_group[0] * (2 * torch.pi / 255)\n",
    "            ry_angle = pixel_group[1] * (2 * torch.pi / 255)\n",
    "            rz_angle = pixel_group[2] * (2 * torch.pi / 255)\n",
    "            rx2_angle = pixel_group[3] * (2 * torch.pi / 255)\n",
    "            \n",
    "            # Apply gates to corresponding qubit\n",
    "            qubit_outputs[f\"qubit_{i}\"] = RX(rx_angle) & RY(ry_angle) & RZ(rz_angle) & RX(rx2_angle)\n",
    "            \n",
    "        return qubit_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantum Layer for Entanglement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumEntanglementLayer(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def add_entanglement_layer(self) -> Dict[str, QReg]:\n",
    "        hwea_params = HardwareEfficientAnsatz(\n",
    "            num_qubits=_NUM_QUBITS,\n",
    "            connectivity_map=_CONNECTIVITY_MAP,\n",
    "            one_qubit_gates=[],\n",
    "            two_qubit_gates=[\"rzz, rxx, rzx, cz\"],\n",
    "        )\n",
    "        return self.HardwareEfficientAnsatz(hwea_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid Quantum Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridQuantumNeuralNetwork(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Instantiate Layer\n",
    "        self.classical_compression_layer = ClassicalCompressionLayer()\n",
    "        self.encoding_layer = QuantumEncodingLayer()\n",
    "        self.entanglement_layer = QuantumEntanglementLayer()\n",
    "\n",
    "        # Import Data\n",
    "        \n",
    "    \n",
    "        # Add Encoding Layer\n",
    "        encoding_out = self.encoding_layer.encode_pixels()\n",
    "\n",
    "        # Add Entanglement Layer\n",
    "        entanglement_out = self.entanglement_layer.add_rzz_layer()\n",
    "\n",
    "        # Add layers to the model\n",
    "        self.add(encoding_out, entanglement_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Classical Compression\n",
    "        compressed_data = self.classical_compression_layer(x)\n",
    "\n",
    "        # Quantum Encoding\n",
    "        encoding_result = self.encoding_layer(compressed_data)\n",
    "\n",
    "        # Quantum Entanglement\n",
    "        entanglement_result = self.entanglement_layer()\n",
    "\n",
    "        # Concatenate quantum and classical outputs\n",
    "        output = self.concatenate(\n",
    "            [encoding_result, entanglement_result, compressed_data]\n",
    "        )\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid_model = HybridQuantumNeuralNetwork()\n",
    "# quantum_program = synthesize(hybrid_model.get_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Above implementation was wrong: Re-trying: Take 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import classiq\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Dict\n",
    "from classiq import Model, synthesize, QReg, QFunc\n",
    "from classiq.builtin_functions import HardwareEfficientAnsatz\n",
    "from classiq.applications.qnn import QLayer\n",
    "from classiq.execution import execute_qnn\n",
    "from classiq.synthesis import SerializedQuantumProgram\n",
    "\n",
    "from classiq.applications.qnn.types import (\n",
    "    MultipleArguments,\n",
    "    SavedResult,\n",
    "    ResultsCollection,\n",
    ")\n",
    "\n",
    "# classiq.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "_NUM_QUBITS =  4\n",
    "_REPS = 1\n",
    "_FULLY_CONNECTED_MESH = [[0, 1], [1, 2], [2, 3], [3, 0]]\n",
    "_LEARNING_RATE = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entanglement(md: Model, prefix: str, in_wire=None) -> Dict[str, QReg]:\n",
    "    if in_wire is not None:\n",
    "        kwargs = { \"in_wires\": { \"IN\": in_wire[\"OUT\"] } }\n",
    "    else: \n",
    "        kwargs = {}\n",
    "    \n",
    "    hwea_params = HardwareEfficientAnsatz(\n",
    "        num_qubits=_NUM_QUBITS,\n",
    "        connectivity_map=_FULLY_CONNECTED_MESH,\n",
    "        reps=_REPS,\n",
    "        one_qubit_gates=[],\n",
    "        two_qubit_gates=[\"rzz\", \"rxx\", \"rzx\"],\n",
    "        parameter_prefix=prefix,\n",
    "    )\n",
    "    \n",
    "    return md.HardwareEfficientAnsatz(hwea_params, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "out1 = add_entanglement(model, \"input_\")\n",
    "out2 = add_entanglement(model, \"weight_\", out1)\n",
    "\n",
    "quantum_program = synthesize(model.get_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(quantum_program: SerializedQuantumProgram, arguments: MultipleArguments) -> ResultsCollection:\n",
    "    return execute_qnn(quantum_program, arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: MODIFY THIS\n",
    "\n",
    "# Post-process the result, returning a dict:\n",
    "# Note: this function assumes that we only care about\n",
    "#   differentiating a single state (|0>)\n",
    "#   from all the rest of the states.\n",
    "#   In case of a different differentiation, this function should change.\n",
    "def post_process(result: SavedResult) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Take in a `SavedResult` with `ExecutionDetails` value type, and return the\n",
    "    probability of measuring |0> which equals the amount of `|0>` measurements\n",
    "    divided by the total amount of measurements.\n",
    "    \"\"\"\n",
    "    counts: dict = result.value.counts\n",
    "    # The probability of measuring |0>\n",
    "    p_zero: float = counts.get(\"0\", 0.0) / sum(counts.values())\n",
    "    return torch.tensor(p_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
