{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "import classiq\n",
    "from classiq import Model, QReg, RX, RY, RZ, synthesize\n",
    "from classiq.builtin_functions import HardwareEfficientAnsatz\n",
    "classiq.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_NUM_QUBITS = 4\n",
    "_CONNECTIVITY_MAP = \"circular\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classical Layer for Image Commpression:\n",
    "The input MNIST images are all 28 × 28. This Classical Layer will firstly center-crop them to 24 × 24 and\n",
    "then down-sample them to 4 × 4 for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalCompressionLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassicalCompressionLayer, self).__init__()\n",
    "        self.center_crop = transforms.CenterCrop((24, 24))\n",
    "        self.down_sample = transforms.Resize((4, 4))\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.center_crop(x)\n",
    "        x = self.down_sample(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantum Layer for Encoding \n",
    "The output of Classical Compression Layer is encoded by this quantum layer into a quantum circuit. We use Angle encoding to encode 4 pixels per qubit using RX, RY, RZ, and RX gate on each qubit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumEncodingLayer(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def encode_pixels(self, pixel_values: torch.Tensor) -> Dict[str, QReg]:\n",
    "        # Split pixel values into groups of 4\n",
    "        pixel_groups = pixel_values.split(4)\n",
    "        \n",
    "        # Initialize dictionary to store qubit outputs\n",
    "        qubit_outputs = {}\n",
    "        \n",
    "        # Encode each group of 4 pixels into angles for RX, RY, RZ, RX gates\n",
    "        for i, pixel_group in enumerate(pixel_groups):\n",
    "            rx_angle = pixel_group[0] * (2 * torch.pi / 255)\n",
    "            ry_angle = pixel_group[1] * (2 * torch.pi / 255)\n",
    "            rz_angle = pixel_group[2] * (2 * torch.pi / 255)\n",
    "            rx2_angle = pixel_group[3] * (2 * torch.pi / 255)\n",
    "            \n",
    "            # Apply gates to corresponding qubit\n",
    "            qubit_outputs[f\"qubit_{i}\"] = RX(rx_angle) & RY(ry_angle) & RZ(rz_angle) & RX(rx2_angle)\n",
    "            \n",
    "        return qubit_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantum Layer for Entanglement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumEntanglementLayer(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def add_entanglement_layer(self) -> Dict[str, QReg]:\n",
    "        hwea_params = HardwareEfficientAnsatz(\n",
    "            num_qubits=_NUM_QUBITS,\n",
    "            connectivity_map=_CONNECTIVITY_MAP,\n",
    "            one_qubit_gates=[],\n",
    "            two_qubit_gates=[\"rzz, rxx, rzx, cz\"],\n",
    "        )\n",
    "        return self.HardwareEfficientAnsatz(hwea_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid Quantum Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridQuantumNeuralNetwork(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Instantiate Layer\n",
    "        self.classical_compression_layer = ClassicalCompressionLayer()\n",
    "        self.encoding_layer = QuantumEncodingLayer()\n",
    "        self.entanglement_layer = QuantumEntanglementLayer()\n",
    "\n",
    "        # Import Data\n",
    "        \n",
    "    \n",
    "        # Add Encoding Layer\n",
    "        encoding_out = self.encoding_layer.encode_pixels()\n",
    "\n",
    "        # Add Entanglement Layer\n",
    "        entanglement_out = self.entanglement_layer.add_rzz_layer()\n",
    "\n",
    "        # Add layers to the model\n",
    "        self.add(encoding_out, entanglement_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Classical Compression\n",
    "        compressed_data = self.classical_compression_layer(x)\n",
    "\n",
    "        # Quantum Encoding\n",
    "        encoding_result = self.encoding_layer(compressed_data)\n",
    "\n",
    "        # Quantum Entanglement\n",
    "        entanglement_result = self.entanglement_layer()\n",
    "\n",
    "        # Concatenate quantum and classical outputs\n",
    "        output = self.concatenate(\n",
    "            [encoding_result, entanglement_result, compressed_data]\n",
    "        )\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid_model = HybridQuantumNeuralNetwork()\n",
    "# quantum_program = synthesize(hybrid_model.get_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Above implementation was wrong: Re-trying: Take 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
